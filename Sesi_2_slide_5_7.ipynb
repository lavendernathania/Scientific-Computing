{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhtfY/NHIaklZA70XUtUpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavendernathania/Scientific-Computing/blob/main/Sesi_2_slide_5_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf0heWz4RQyg",
        "outputId": "b6c1d8f2-13a2-4281-d07e-a973fd28fb00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix is diagonally dominant\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = [[8, 3, -3], [-2, -8, 5], [3, 5, 10]]\n",
        "diag = np.diag(np.abs(a))\n",
        "off_diag = np.sum(np.abs(a), axis=1) - diag\n",
        "if np.all(diag > off_diag):\n",
        "  print('matrix is diagonally dominant')\n",
        "else:\n",
        "  print('NOT diagonally dominant')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = [[9, 1, -7], [-2, 1, 5], [3, 5, 1]]\n",
        "\n",
        "diag = np.diag(np.abs(a))\n",
        "\n",
        "off_diag = np.sum(np.abs(a), axis =1) - diag\n",
        "\n",
        "if np.all(diag > off_diag) :\n",
        "  print('Matrix is diagonally dominant')\n",
        "else:\n",
        "  print('NOT diagonally dominant')\n",
        "\n",
        "x1 = 0\n",
        "x2 = 0\n",
        "x3 = 0\n",
        "epsilon = 0.01\n",
        "converged = False\n",
        "\n",
        "x_old = np.array([x1, x2, x3])"
      ],
      "metadata": {
        "id": "0Eo3nG6DTlyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d87c9ca-51e9-492b-b2b0-d34e40ea4f3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT diagonally dominant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Iteration results')\n",
        "print(' k, x1, x2, x3')\n",
        "for k in range(1, 50):\n",
        "  x1 = (14-3*x2+3*x3)/8\n",
        "  x2 = (5+2*x1-5*x3)/(-8)\n",
        "  x3 = (-8-3*x1-5*x2)/(10)\n",
        "  x = np.array([x1, x2, x3])\n",
        "\n",
        "  dx = np.sqrt(np.dot(x-x_old, x-x_old))\n",
        "\n",
        "  print(\"%d, %.4f, %.4f, %.4f\"%(k, x1, x2, x3))\n",
        "  if dx < epsilon:\n",
        "    converged = True\n",
        "    print('Converged!')\n",
        "    break\n",
        "\n",
        "  x_old = x\n",
        "if not converged:\n",
        "  print('Not converge, increadse the # of iterations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDrbX3TPUrKO",
        "outputId": "e9846aeb-d129-45e9-afc1-e9b87b035c79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration results\n",
            " k, x1, x2, x3\n",
            "1, 1.8508, -1.5838, -0.5633\n",
            "2, 2.1327, -1.5103, -0.6847\n",
            "3, 2.0596, -1.5678, -0.6340\n",
            "4, 2.1002, -1.5463, -0.6569\n",
            "5, 2.0835, -1.5565, -0.6468\n",
            "6, 2.0911, -1.5520, -0.6513\n",
            "Converged!\n"
          ]
        }
      ]
    }
  ]
}